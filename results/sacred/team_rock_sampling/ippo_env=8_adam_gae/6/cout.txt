[INFO 13:58:52] pymarl Running command 'my_main'
[INFO 13:58:52] pymarl Started run with ID "6"
[DEBUG 13:58:52] my_main Started
[INFO 13:58:52] my_main Experiment Parameters:
[INFO 13:58:52] my_main 

{   'accumulated_episodes': 8,
    'action_selector': 'multinomial',
    'agent': 'n_rnn',
    'agent_output_type': 'pi_logits',
    'batch_size': 64,
    'batch_size_run': 8,
    'buffer_cpu_only': True,
    'buffer_size': 64,
    'checkpoint_path': '',
    'critic_coef': 0.5,
    'critic_lr': 0.0005,
    'entropy': 0.01,
    'env': 'team_rock_sampling',
    'env_args': {   'env_args': {   'horizon': 300},
                    'map_name': 'team_rock_sampling',
                    'seed': 784941904},
    'eps_clip': 0.2,
    'epsilon_anneal_time': 100000,
    'epsilon_finish': 0.0,
    'epsilon_start': 1.0,
    'evaluate': False,
    'gae_lambda': 0.95,
    'gain': 0.01,
    'gamma': 0.99,
    'grad_norm_clip': 10,
    'label': 'default_label',
    'learner': 'ppo_learner',
    'learner_log_interval': 2000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 2000,
    'lr': 0.0005,
    'mac': 'basic_mac',
    'mask_before_softmax': True,
    'mini_epochs': 8,
    'name': 'ippo_env=8_adam_gae',
    'obs_agent_id': True,
    'obs_last_action': True,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'repeat_id': 1,
    'rnn_hidden_dim': 64,
    'run': 'default',
    'runner': 'parallel',
    'runner_log_interval': 2000,
    'save_model': False,
    'save_model_interval': 2000000,
    'save_probs': True,
    'save_replay': False,
    'seed': 784941904,
    't_max': 10050000,
    'test_greedy': True,
    'test_interval': 2000,
    'test_nepisode': 200,
    'use_cuda': False,
    'use_layer_norm': False,
    'use_orthogonal': False,
    'use_tensorboard': False,
    'use_value_norm': False}

[INFO 13:58:52] my_main Beginning training for 10050000 timesteps
/home/elem/repos/MARL/pymarl/src/components/episode_buffer.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  v = th.tensor(v, dtype=dtype, device=self.device)
[INFO 13:58:52] my_main t_env: 2400 / 10050000
[INFO 13:58:52] my_main Estimated time left: 30 minutes, 22 seconds. Time passed: 0 seconds
[INFO 13:59:15] my_main Recent Stats | t_env:       2400 | Episode:        8
ep_length_mean:          300.0000	epsilon:                   1.0000	return_mean:             -714.5000	return_std:              637.1850
test_ep_length_mean:     300.0000	test_return_mean:        -1471.9800	test_return_std:         253.4516	
[INFO 13:59:16] my_main t_env: 4800 / 10050000
[INFO 13:59:16] my_main Estimated time left: 1 days, 3 hours, 21 minutes, 44 seconds. Time passed: 24 seconds
[INFO 13:59:43] my_main Recent Stats | t_env:       4800 | Episode:       16
ep_length_mean:          300.0000	epsilon:                   0.9760	return_mean:             -1121.6250	return_std:              526.3958
test_ep_length_mean:     300.0000	test_return_mean:        -1498.4800	test_return_std:         164.1371	
[INFO 13:59:44] my_main t_env: 7200 / 10050000
[INFO 13:59:44] my_main Estimated time left: 1 days, 8 hours, 52 minutes, 28 seconds. Time passed: 52 seconds
