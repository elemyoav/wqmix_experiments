[INFO 03:32:25] pymarl Running command 'my_main'
[INFO 03:32:25] pymarl Started run with ID "2"
[DEBUG 03:32:25] my_main Started
[INFO 03:32:25] my_main Experiment Parameters:
[INFO 03:32:25] my_main 

{   'accumulated_episodes': 8,
    'action_selector': 'multinomial',
    'agent': 'n_rnn',
    'agent_output_type': 'pi_logits',
    'batch_size': 64,
    'batch_size_run': 8,
    'buffer_cpu_only': True,
    'buffer_size': 64,
    'checkpoint_path': '',
    'critic_coef': 0.5,
    'critic_lr': 0.0005,
    'entropy': 0.01,
    'env': 'team_rock_sampling',
    'env_args': {   'env_args': {   'horizon': 30},
                    'map_name': 'team_rock_sampling',
                    'seed': 150707724},
    'eps_clip': 0.2,
    'epsilon_anneal_time': 100000,
    'epsilon_finish': 0.0,
    'epsilon_start': 0.0,
    'evaluate': False,
    'gae_lambda': 0.95,
    'gain': 0.01,
    'gamma': 0.99,
    'grad_norm_clip': 10,
    'label': 'default_label',
    'learner': 'ppo_learner',
    'learner_log_interval': 2000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 2000,
    'lr': 0.0005,
    'mac': 'basic_mac',
    'mask_before_softmax': True,
    'mini_epochs': 8,
    'name': 'ippo_env=8_adam_gae',
    'obs_agent_id': True,
    'obs_last_action': True,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'repeat_id': 1,
    'rnn_hidden_dim': 64,
    'run': 'default',
    'runner': 'parallel',
    'runner_log_interval': 2000,
    'save_model': False,
    'save_model_interval': 2000000,
    'save_probs': True,
    'save_replay': False,
    'seed': 150707724,
    't_max': 10050000,
    'test_greedy': True,
    'test_interval': 20000,
    'test_nepisode': 24,
    'use_cuda': True,
    'use_layer_norm': True,
    'use_orthogonal': True,
    'use_tensorboard': False,
    'use_value_norm': True}

[INFO 03:32:30] my_main Beginning training for 10050000 timesteps
/home/elem/repos/MARL/pymarl/src/components/episode_buffer.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  v = th.tensor(v, dtype=dtype, device=self.device)
[INFO 03:32:30] my_main t_env: 240 / 10050000
[INFO 03:32:30] my_main Estimated time left: 3 minutes, 35 seconds. Time passed: 0 seconds
[INFO 03:32:36] my_main Recent Stats | t_env:       2160 | Episode:       72
actor_loss:               -0.0451	advantage_mean:            0.0000	critic_loss:               0.4919	entropy_loss:              6.2558
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.1700	lr:                        0.0005
return_mean:             -133.1250	return_std:               26.0549	target_mean:               0.0000	test_ep_length_mean:      30.0000
test_return_mean:        -135.2083	test_return_std:          33.3054	
[INFO 03:32:50] my_main Recent Stats | t_env:       4320 | Episode:      144
actor_loss:               -0.0491	advantage_mean:            0.0000	critic_loss:               0.1326	entropy_loss:              6.2130
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.2413	lr:                        0.0005
return_mean:             -115.6389	return_std:               89.6858	target_mean:              -1.0693	
[INFO 03:33:10] my_main Recent Stats | t_env:       6480 | Episode:      216
actor_loss:               -0.1249	advantage_mean:            0.0000	critic_loss:               0.0053	entropy_loss:              6.1086
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.1367	lr:                        0.0005
return_mean:             -111.6528	return_std:               90.0017	target_mean:              -0.8750	
[INFO 03:33:33] my_main Recent Stats | t_env:       8640 | Episode:      288
actor_loss:               -0.0306	advantage_mean:           -0.0000	critic_loss:               0.1067	entropy_loss:              5.8732
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.1821	lr:                        0.0005
return_mean:             -108.4861	return_std:               18.7209	target_mean:              -0.6240	
[INFO 03:34:00] my_main Recent Stats | t_env:      10800 | Episode:      360
actor_loss:               -0.0402	advantage_mean:           -0.0000	critic_loss:               0.1371	entropy_loss:              5.7996
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.5123	lr:                        0.0005
return_mean:             -76.3333	return_std:               91.7463	target_mean:              -0.1805	
[INFO 03:34:21] my_main Recent Stats | t_env:      12960 | Episode:      432
actor_loss:               -0.1396	advantage_mean:           -0.0000	critic_loss:               0.0033	entropy_loss:              5.5114
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.2421	lr:                        0.0005
return_mean:             -62.7083	return_std:               87.8064	target_mean:              -0.0018	
[INFO 03:34:56] my_main Recent Stats | t_env:      15120 | Episode:      504
actor_loss:               -0.1354	advantage_mean:           -0.0000	critic_loss:               0.0043	entropy_loss:              5.2111
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.3645	lr:                        0.0005
return_mean:             -57.9444	return_std:               15.0848	target_mean:               0.5462	
[INFO 03:35:23] my_main Recent Stats | t_env:      17280 | Episode:      576
actor_loss:               -0.0220	advantage_mean:            0.0000	critic_loss:               0.7544	entropy_loss:              5.1089
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.3627	lr:                        0.0005
return_mean:             -45.4722	return_std:               14.3981	target_mean:               0.9964	
[INFO 03:35:53] my_main Recent Stats | t_env:      19440 | Episode:      648
actor_loss:               -0.1103	advantage_mean:           -0.0000	critic_loss:               0.0026	entropy_loss:              4.9346
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.5026	lr:                        0.0005
return_mean:             -18.2083	return_std:              174.5197	target_mean:               0.9194	
[INFO 03:36:04] my_main t_env: 20400 / 10050000
[INFO 03:36:04] my_main Estimated time left: 1 days, 5 hours, 37 minutes, 42 seconds. Time passed: 3 minutes, 34 seconds
[INFO 03:36:21] my_main Recent Stats | t_env:      21600 | Episode:      720
actor_loss:               -0.0282	advantage_mean:           -0.0000	critic_loss:               0.4814	entropy_loss:              4.9712
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.8512	lr:                        0.0005
return_mean:             -35.9722	return_std:               13.2644	target_mean:               1.2923	test_ep_length_mean:      30.0000
test_return_mean:         -8.5833	test_return_std:          14.9914	
[INFO 03:37:17] my_main Recent Stats | t_env:      23760 | Episode:      792
actor_loss:               -0.0379	advantage_mean:           -0.0000	critic_loss:               0.4525	entropy_loss:              5.1287
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 4.1124	lr:                        0.0005
return_mean:             -10.2917	return_std:              172.1654	target_mean:               1.3341	
[INFO 03:39:09] my_main Recent Stats | t_env:      25920 | Episode:      864
actor_loss:               -0.0959	advantage_mean:            0.0000	critic_loss:               0.0087	entropy_loss:              4.9116
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.4694	lr:                        0.0005
return_mean:             -16.4167	return_std:              176.8880	target_mean:               1.0618	
[INFO 03:41:03] my_main Recent Stats | t_env:      28080 | Episode:      936
actor_loss:               -0.1206	advantage_mean:            0.0000	critic_loss:               0.0033	entropy_loss:              4.6264
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.7561	lr:                        0.0005
return_mean:             -41.9722	return_std:               19.6341	target_mean:               1.0477	
[INFO 03:41:35] my_main Recent Stats | t_env:      30240 | Episode:     1008
actor_loss:               -0.1123	advantage_mean:            0.0000	critic_loss:               0.0015	entropy_loss:              4.3218
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.7905	lr:                        0.0005
return_mean:             -27.4167	return_std:               13.7677	target_mean:               0.9154	
[INFO 03:42:28] my_main Recent Stats | t_env:      32400 | Episode:     1080
actor_loss:               -0.0290	advantage_mean:            0.0000	critic_loss:               0.0857	entropy_loss:              4.1980
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.2021	lr:                        0.0005
return_mean:             -20.2361	return_std:               11.9181	target_mean:               0.9001	
[INFO 03:43:41] my_main Recent Stats | t_env:      34560 | Episode:     1152
actor_loss:               -0.0330	advantage_mean:           -0.0000	critic_loss:               0.2959	entropy_loss:              4.3514
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.4236	lr:                        0.0005
return_mean:               0.0417	return_std:              122.6974	target_mean:               0.8084	
[INFO 03:44:35] my_main Recent Stats | t_env:      36720 | Episode:     1224
actor_loss:               -0.0373	advantage_mean:            0.0000	critic_loss:               0.0754	entropy_loss:              4.5521
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.2239	lr:                        0.0005
return_mean:              -1.5694	return_std:              176.1059	target_mean:               0.6222	
[INFO 03:45:48] my_main Recent Stats | t_env:      38880 | Episode:     1296
actor_loss:               -0.1237	advantage_mean:            0.0000	critic_loss:               0.0014	entropy_loss:              4.2147
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.5511	lr:                        0.0005
return_mean:             -16.2083	return_std:               89.7060	target_mean:               0.3968	
[INFO 03:46:52] my_main t_env: 40560 / 10050000
[INFO 03:46:52] my_main Estimated time left: 3 days, 17 hours, 21 minutes, 44 seconds. Time passed: 14 minutes, 22 seconds
[INFO 03:47:14] my_main Recent Stats | t_env:      41040 | Episode:     1368
actor_loss:               -0.1189	advantage_mean:            0.0000	critic_loss:               0.0009	entropy_loss:              3.9201
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.4725	lr:                        0.0005
return_mean:             -27.6806	return_std:               17.5783	target_mean:               0.4679	test_ep_length_mean:      30.0000
test_return_mean:         -6.8750	test_return_std:           5.7758	
[INFO 03:48:12] my_main Recent Stats | t_env:      43200 | Episode:     1440
actor_loss:               -0.0355	advantage_mean:           -0.0000	critic_loss:               0.0842	entropy_loss:              4.2011
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.7021	lr:                        0.0005
return_mean:             -18.9722	return_std:               11.8953	target_mean:               0.6438	
[INFO 03:49:04] my_main Recent Stats | t_env:      45360 | Episode:     1512
actor_loss:               -0.0342	advantage_mean:            0.0000	critic_loss:               0.0881	entropy_loss:              4.1492
ep_length_mean:           30.0000	epsilon:                   0.0000	grad_norm:                 0.2818	lr:                        0.0005
return_mean:             -10.4306	return_std:               85.9017	target_mean:               0.5126	
